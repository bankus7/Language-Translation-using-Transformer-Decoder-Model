{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Language-Translation-using-Transformer-Decoder-Model/blob/main/Language_Translation_using_Transformer_Decoder_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdtrlAhvIHY"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* understand the big picture of transformers\n",
        "* explore masking of transformers\n",
        "* implement transformer decoder and understand its architecture\n",
        "* apply learning on a machine translation problem"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Big Picture"
      ],
      "metadata": {
        "id": "Tv8TQrtfwaNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/NLP_Pipeline.png\" width=700px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "ni6YCBwE7d_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer architecture follows an encoder-decoder structure:\n",
        "\n",
        "- the ***encoder***, on the left-hand side, is tasked with mapping an input sequence to a sequence of continuous representations;\n",
        "- the ***decoder***, on the right-hand side, receives the output of the encoder together with the decoder output at the previous time step to generate an output sequence."
      ],
      "metadata": {
        "id": "4xCXKCLBobfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformer decoder generates sequences autoregressively by attending to previously generated positions using masked self-attention, attending to the encoder's output using encoder-decoder attention, applying feed-forward networks, and utilizing positional encodings. This architecture allows the decoder to produce coherent and contextually accurate sequences in various natural language processing tasks"
      ],
      "metadata": {
        "id": "bqM7uCmtEt5c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RH8Ecq9sbYU"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "Ms8SJA8jELck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part A** : Building Encoder Transformer"
      ],
      "metadata": {
        "id": "qDk0xc-_gbV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The concepts for Transformer encoder have been discussed in Assignment 3 and the same steps are implemented here for creating a decoder network."
      ],
      "metadata": {
        "id": "FuUJwJFNE8jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define TransformerEncoder class to be used in model building"
      ],
      "metadata": {
        "id": "vtZo2HU5IpgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim    # Dimension of embedding. 4 in the dummy example\n",
        "        self.dense_dim = dense_dim    # No. of neurons in dense layer\n",
        "        self.num_heads = num_heads    # No. of heads for MultiHead Attention layer\n",
        "        self.attention = layers.MultiHeadAttention(   # MultiHead Attention layer\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "        )                                 # So output dimension is also embed_dim\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    # Call function based on figure above\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "            print(f\"**test: mask in not None. mask = {mask}\")\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)  # Query: inputs, Value: inputs, Keys: Same as Values by default\n",
        "                                                  # Q: Can you see how this is self attention? A: all args are the same\n",
        "        proj_input = self.layernorm_1(inputs + attention_output) # LayerNormalization; + Recall cat picture\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)  # LayerNormalization + Residual connection\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return"
      ],
      "metadata": {
        "id": "XW-WstYmH-4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Embedding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Learn position- embedding vectors the same way we learn to embed word indices.\n",
        "*   Proceed to **add** our position embeddings to the corresponding word embeddings, to obtain a position-aware word embedding.\n",
        "*   This technique is called “positional embedding.”\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WcVnGSnpSFGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/PositionalEmbedding.png\" width=700px/>\n"
      ],
      "metadata": {
        "id": "0n04kGhBbQCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Encoder%20Embedding.png\" width=650px/>\n",
        "</center>\n",
        "\n",
        "![]()"
      ],
      "metadata": {
        "id": "k3VrrCylc6q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: In the picture above:\n",
        "\n",
        "\n",
        "*   What is the embedding dimension for both the layers? - 3\n",
        "*   How many rows would the token embedding layer have?  - 20000 (vocab size)\n",
        "*   How many rows would the postional embedding layer have? - 600 (seq length)\n",
        "*   Where do we get the indices in token embedding layer? - from TextVectorization\n",
        "*   Where do we get the indices in token embedding layer? - We explicitly define a range\n",
        "\n"
      ],
      "metadata": {
        "id": "AMOrn4pQeefD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define PositionalEmbedding class to be used in model building"
      ],
      "metadata": {
        "id": "jSibMhQ0I3T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        # input_dim = (token) vocabulary size,  output_dim = embedding size\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.token_embeddings = layers.Embedding(       # Q: what is input_dim and output_dim? A: vocab size, embedding dim\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(    # Q: Why input_dim = seq_length?  A: there are seq_len (here 600) no. of possible positions\n",
        "            input_dim=sequence_length, output_dim=output_dim)   # Q: What is the vocab for this Embedding layer ? A: seq_length\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):   # inputs will be a batch of sequences (batch, seq_len)\n",
        "        length = tf.shape(inputs)[-1]     # lenght will just be sequence length\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # indices for input to positional embedding\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions     # ADD the embeddings\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):  # makes this layer a mask-generating layer\n",
        "        return tf.math.not_equal(inputs, 0)     #mask will get propagated to the next layer.\n",
        "\n",
        "    # When using custom layers, this enables the layer to be reinstantiated from its config dict,\n",
        "    # which is useful during model saving and loading.\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "qCAWpi5zGUlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAY BE REMOVED\n",
        "a = tf.constant([1,0,2,0,3]) # a is a tensor\n",
        "tf.math.not_equal(a, 0) # which elements of 'a' are not equal to 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwDciZc2g3za",
        "outputId": "0ebf3d3c-1196-4c01-d1d1-c70377d41e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=bool, numpy=array([ True, False,  True, False,  True])>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TransformerEncoder model definition with Positional Embedding"
      ],
      "metadata": {
        "id": "ZVD5IzTuJD29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Combining the Transformer encoder with positional embedding\n",
        "#  The values below are for the classificaiton problem. We will change them for the tranlation example\n",
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")  # Q: Why is the input expected to have dtype int? A: Inputs coming from TextVectorization layer.\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "print(f\"Token embedding weights: {256*20000}\")\n",
        "print(f\"Position embedding weights: {256*600}\")\n",
        "print(f\"Total no. of weights: {256*20000 + 256*600}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uaobuC7WZ0w",
        "outputId": "e9759328-563f-4f15-a411-f0b99743ed45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**test: mask in not None. mask = Tensor(\"transformer_encoder/strided_slice:0\", shape=(None, 1, None), dtype=bool)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " positional_embedding (Posi  (None, None, 256)         5273600   \n",
            " tionalEmbedding)                                                \n",
            "                                                                 \n",
            " transformer_encoder (Trans  (None, None, 256)         543776    \n",
            " formerEncoder)                                                  \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 256)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5817633 (22.19 MB)\n",
            "Trainable params: 5817633 (22.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Token embedding weights: 5120000\n",
            "Position embedding weights: 153600\n",
            "Total no. of weights: 5273600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part B** : Building Decoder Transformer"
      ],
      "metadata": {
        "id": "orBRzfHAebIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder - Decoder Overview\n",
        "\n",
        "**Encoder - Encodes the input as some representation**\n",
        "\n",
        "**Decoder - Uses the encoded representation (and targets) to decode these representation as per the target.**\n",
        "\n",
        "*   Encoders - can be CNNs, RNNs, FFNs\n",
        "*   Decoders - can be CNNs, RNNs, FFNs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b2Z0_zLTsYPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples:\n",
        "* Problem: Predict description in text from images.\n",
        "  - Encoder - CNN\n",
        "  - Decoder - RNN\n",
        "\n",
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Encoder%20Decoder%20Overview.png\" width=350px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "Jw9VGiLy2Nik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Problem: Language Translation\n",
        "  - Encoder - RNN\n",
        "  - Decoder - RNN\n",
        "\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/EncoderDecoder.jpeg\" width=600px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "3UxReBBp2NyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Problem: Language Translation\n",
        "    - Transformer Encoder\n",
        "    - Transformet Decoder\n",
        "\n",
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Transformer%20Network.png\" width=300px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "KzlzttwC2-I1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training,\n",
        "* **An encoder model turns the source sequence into an intermediate representation.**\n",
        "* **A decoder is trained to predict the next token i** in the target sequence by looking at both\n",
        "    - previous tokens (0 to i - 1) and\n",
        "    - the encoded source sequence\n",
        "    "
      ],
      "metadata": {
        "id": "d3LdyPKhsYWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During inference, we don’t have access to the target sequence—we’re trying to predict it from scratch. We’ll have to generate it one token at a time:\n",
        "1. We obtain the encoded source sequence from the encoder.\n",
        "2. The decoder starts by looking at the encoded source sequence as well as an initial “seed” token (such as the string \"[start]\"), and uses them to predict the\n",
        "first real token in the sequence.\n",
        "3. The predicted sequence so far is fed back into the decoder, which generates the next token, and so on, until it generates a stop token (such as the string \"[end]\")."
      ],
      "metadata": {
        "id": "Wq5yUiVhudHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Transformer%20gif.gif\" width=750px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "2Do0zZWCuiJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQO73b-r4y0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masking is needed to prevent the attention mechanism of a transformer from “cheating” in the decoder when training (on a translating task for instance). This kind of “ cheating-proof masking” is not present in the encoder side."
      ],
      "metadata": {
        "id": "7Dkb0qlNSsAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the sequence: “I love it”, then the expected prediction for the token at position one (“I”) is the token at the next position (“love”). Similarly the expected prediction for the tokens “I love” is “it”.\n",
        "\n",
        "We do not want the attention mechanism to share any information regarding the token at the next positions, when giving a prediction using all the previous tokens.\n",
        "\n",
        "To ensure that this is done, we mask future positions (setting them to -inf) before the softmax step in the self-attention calculation."
      ],
      "metadata": {
        "id": "oR2VCAGWTWHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding mask"
      ],
      "metadata": {
        "id": "dLhi72ah-9na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding is a special form of masking where the masked steps are at the start or the end of a sequence. Padding comes from the need to encode sequence data into contiguous batches: in order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences."
      ],
      "metadata": {
        "id": "Zg2lNXdplnb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The Embedding layer is capable of generating a “mask” that corresponds to its input data.\n",
        "\n",
        "* By default, this option isn’t active—you can turn it on by passing mask_zero=True to your Embedding layer.\n",
        "\n",
        "* You can retrieve the mask with the compute_mask() method:"
      ],
      "metadata": {
        "id": "0fsvrm8dRX4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An example to understand Padding Masking"
      ],
      "metadata": {
        "id": "jvl9mkDal6zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding mask\n",
        "embedding_layer_ = layers.Embedding(input_dim=10, output_dim=256, mask_zero=True)\n",
        "some_input = [\n",
        "  [4,3,2,1,0,0,0],\n",
        "  [5,4,3,2,1,0,0],\n",
        "  [2,1,0,0,0,0,0]]\n",
        "d_mask = embedding_layer_.compute_mask(some_input)\n",
        "print(d_mask)\n",
        "print(tf.cast(d_mask, dtype=\"int32\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Md-LHZtQ7Zp",
        "outputId": "e7414542-ea67-4b25-e033-8cf76df969a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True  True  True False False False]\n",
            " [ True  True  True  True  True False False]\n",
            " [ True  True False False False False False]], shape=(3, 7), dtype=bool)\n",
            "tf.Tensor(\n",
            "[[1 1 1 1 0 0 0]\n",
            " [1 1 1 1 1 0 0]\n",
            " [1 1 0 0 0 0 0]], shape=(3, 7), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Causal Padding"
      ],
      "metadata": {
        "id": "Iuyzd5P7Q5Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **The Transformer Decoder is order-agnostic: it looks at the entire target sequence at once.**\n",
        "*   If it were allowed to use its entire input, it would simply learn to copy input step N+1 to location N in the output.\n",
        "\n",
        "*  **Solution: mask the upper half of the pairwise attention matrix to prevent the model from paying any attention to information from the future**\n",
        "*  We'll see this in the method get_causal_attention_mask(self, inputs) inside the decoder class\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "-TNaWfPasli3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Self%20Attention%20Scores.png\" width=600px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "1-U2aT2c58-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Multihead%20Attention.png\" width=600px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "IFAiWsE3kK7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume sequence length is 5\n",
        "j = normal_range = tf.range(5)\n",
        "i = with_new_axis = tf.range(5)[:, tf.newaxis]\n",
        "# with_2new_axis = tf.range(10)[:, tf.newaxis, tf.newaxis]"
      ],
      "metadata": {
        "id": "7DIIseZQWPsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normal_range)\n",
        "print(with_new_axis)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv-vP3TrWWaP",
        "outputId": "5da73961-3ea1-4f8a-c483-6578ff5d45ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]], shape=(5, 1), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# j is broadcasted; booleans are cast to int32\n",
        "d_mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "print(d_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nqm6dAHaF4G",
        "outputId": "a996b911-6291-47e2-ec49-d44cdbebe58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 0 0 0 0]\n",
            " [1 1 0 0 0]\n",
            " [1 1 1 0 0]\n",
            " [1 1 1 1 0]\n",
            " [1 1 1 1 1]], shape=(5, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_mask = tf.reshape(d_mask, (1, 5, 5))\n",
        "print(d_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK_XMJCfap91",
        "outputId": "08a318c8-5c06-44ad-ae24-252819e839f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 0 0 0 0]\n",
            "  [1 1 0 0 0]\n",
            "  [1 1 1 0 0]\n",
            "  [1 1 1 1 0]\n",
            "  [1 1 1 1 1]]], shape=(1, 5, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define tile multiplier for tiling\n",
        "batch_size = 2\n",
        "mult = tf.concat(\n",
        "    [tf.expand_dims(batch_size, -1),\n",
        "      tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "print(tf.expand_dims(batch_size, -1))\n",
        "print(tf.constant([1, 1], dtype=tf.int32))\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSbwK1f3bIuU",
        "outputId": "9c651ac9-d68b-4f4d-bd30-7df0f92ffebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2], shape=(1,), dtype=int32)\n",
            "tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
            "tf.Tensor([2 1 1], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tile the mask to replicate across batchsize\n",
        "causal_mask_ = tf.tile(d_mask, mult)\n",
        "print(causal_mask_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_YgbB3zeu8x",
        "outputId": "7994e92a-b99a-48f1-91d8-79eaaac8ced7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 0 0 0 0]\n",
            "  [1 1 0 0 0]\n",
            "  [1 1 1 0 0]\n",
            "  [1 1 1 1 0]\n",
            "  [1 1 1 1 1]]\n",
            "\n",
            " [[1 0 0 0 0]\n",
            "  [1 1 0 0 0]\n",
            "  [1 1 1 0 0]\n",
            "  [1 1 1 1 0]\n",
            "  [1 1 1 1 1]]], shape=(2, 5, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above:\n",
        "\n",
        "sequence length = 5\n",
        "\n",
        "batch size = 2"
      ],
      "metadata": {
        "id": "bTB56QC6gwPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know more about masking, refer [here](https://www.tensorflow.org/guide/keras/masking_and_padding)."
      ],
      "metadata": {
        "id": "YDJ5XdcUU6B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Decoder"
      ],
      "metadata": {
        "id": "jccpLKpUEwCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Two windows for visualization)"
      ],
      "metadata": {
        "id": "Cio6NfkU9VGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # Define the layers. Let's point them out in the diagram\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        # Now we have 2 MultiHead Attention layers - one for self attention and one for generalized attention\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True #ensures that the layer will propagate its input mask to its outputs;\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1])) # sequence_length == input_shape[1]\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "              tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None): # two inputs: decoder i/p and encoder o/p\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        # print(f\"*** test: mask = {mask}\")\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask) # union of 0s\n",
        "            # print(f\"**** test padding mask: {padding_mask}\")\n",
        "        attention_output_1 = self.attention_1(    # Q: What kind of attention?  A: self attention\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask) # Q: What will the causal_mask do? A: makes attention score of a query independent of future tokens\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(  # Q: Is this self attention? A: No. This is generalised attention\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,    # Key and Value coming from encoder\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ],
      "metadata": {
        "id": "T92X85GUFCLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Transformer%20Network_2.png?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHQaCmV1LW5vcnRoLTEiRzBFAiEAmOZQhT%2BYM40tIrgSCC0juQ3jYb2AAM%2F1Fbz6dD8McLICIHg%2Fvrzjk8lvADAhmWpZrYL9TF3PwvkzKpdWA8hZeRQoKu0CCM3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMOTc1MDUwMDY4NjU4IgyeGfj2LlL0RNsVYPMqwQJM4d9h4CmJwEyTBC7qZEzc29kl0a%2FrmErIOHAztB%2FrvmsLwfZSviafkN0S0Rgnb9ZUlQLlOLgmJAh%2Boo5wqCAD6Vph5HKDP0UmiithH%2BlXOUIiDE51ykTUEA3w1iSSHMyOs7vDBsLp%2FMFpvpCG3V2XnlQ5Iqgo422ee763aDs%2FzuanCRZpfGDaLTo%2BgTWY0vQntjWJILYrZeOw0tpLpzZArag7KROagc0J8JjBvK0M%2Fz02ApRdrd4sspTDVFraDlGzFJekxjfCDEkf0gSQy7gutoZ2hujhd%2BonPc2Sob988wEY1BUTJWathwBoXphrbMZIS6LhUp1rTnDl8w7hv54XZ4ORo9w4oXVsZdG%2FDbp2dUX6yVHFY3mjMGdU6fEQ1j2AlzySCTm4T%2FzJpXst4CisnbG6opNd6Os2b78VkYfQnKAwtdPmsQY6swKV5d%2BjoEU9poWR0HUudhbWdbIOfv1xKG64htIRW3NpNgi0OonJi5zOPTw5aWoAvi5hbnA7akONMJtwKRTgl9t30qtpFA8DwvmNL%2BUt%2FNsayqUy%2BrKPtD%2FtfVYyu82iXyxz4EyCSXPTgcCREW61a0z%2F8HtRH76JayEUAc7PAypjS861xn7SFWDzldlYWE8H2bDvjOQdf82VBKm67cP5CPWaxKpPkpTJFAR82hOQeFordG1wctY1YO5AOZnqv8Wd%2B7Tz9rQYNYk9xUihZZHgrvYzMuQWKcj%2By2eMBR7uWxP5LR48KBnL6edR4ZCv5H5LYCGjIREzJAImRO9qbDptQLHW%2B943UkCxOSqNdCIQjgRoWe84M93lB6rTQjLowcqWYU9YJDY9V73Jfw8Qz3mx6HxtnhdV&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240507T120236Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIA6GBMDKKZK2QSB44A%2F20240507%2Feu-north-1%2Fs3%2Faws4_request&X-Amz-Signature=ad2f5678c3b61b7091e67e98753ab19179e6660ac0571ca3bcb9314fd0e1058d\" width=350px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "3Mix-Vvd9Byv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English to spanish translation\n",
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # Q: First arg acts like a 'vocabulary' for pos embedding layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) #Q: What are these arguments? A: embedding dimension, no. of neurons in dense layer, no. of head in multi-head attention layer\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs) # Q: What are the call arguments in the picture? A: See tutorial video\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # Note that there are two input layers\n",
        "transformer.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ltu1dmtHoyV",
        "outputId": "872f44f0-6b1f-41ad-c0fd-7db2f1c2d1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**test: mask in not None. mask = Tensor(\"transformer_encoder_1/strided_slice:0\", shape=(None, 1, None), dtype=bool)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            5273600   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            5273600   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_1[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_2[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, None, 20000)          5140000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24102176 (91.94 MB)\n",
            "Trainable params: 24102176 (91.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Machine Translation Example\n",
        "\n",
        "English to Spanish translation"
      ],
      "metadata": {
        "id": "zsFTQP9S6s-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the data"
      ],
      "metadata": {
        "id": "B0Y2NmDV7lF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip -d /content\n"
      ],
      "metadata": {
        "id": "POk4n-kE7Z6m",
        "outputId": "0abd1ba8-ea49-4cb7-b195-c4c60cd46a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-22 11:31:02--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.218.207, 108.177.11.207, 173.194.217.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.218.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-03-22 11:31:02 (328 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rows of the dataset\n",
        "!tail spa-eng/spa.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxaC6lh95Ox2",
        "outputId": "7d0303b0-42a0-4fb9-d597-a43209933e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can't view Flash content on an iPad. However, you can easily email yourself the URLs of these web pages and view that content on your regular computer when you get home.\tNo puedes ver contenido en Flash en un iPad. Sin embargo, puedes fácilmente enviarte por correo electrónico las URL's de esas páginas web y ver el contenido en tu computadora cuando llegas a casa.\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tUn error que cometen a menudo los jóvenes es el de comenzar a aprender demasiadas lenguas al mismo tiempo, porque subestiman sus dificultades y sobrestiman sus propias capacidades para aprenderlas.\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\tNo importa cuánto insistas en convencer a la gente de que el chocolate es vainilla, seguirá siendo chocolate, aunque puede que te convenzas a ti mismo y a algunos otros de que es vainilla.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\tEn 1969, Roger Miller grabó una canción llamada \"Tú no quieres mi amor\". Hoy, esta canción es más conocida como \"En el verano\". Es la primera canción que escribió y cantó que se convirtió popular.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\tUn niño que es hablante nativo normalmente sabe muchas cosas acerca de su lengua que un hablante no nativo que lo haya estado estudiando durante muchos años no sabe todavía y que quizá no sabrá nunca.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\tHay cuatro causas principales de muertes relacionadas con el alcohol. Lesión por un accidente automovilístico o violencia es una. Enfermedades como cirrosis del hígado, cáncer, enfermedades del corazón y del sistema circulatorio son las otras.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\tHay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente dinero para la educación universitaria de sus hijos.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\tUna huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tComo suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente página encontrada por Google y espero encontrar algo menos irritante.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\tSi quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing: Separating input and output sequences\n",
        "text_file = \"spa-eng/spa.txt\"\n",
        "\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "text_pairs = []\n",
        "\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\"\n",
        "    text_pairs.append((english, spanish))\n",
        "\n",
        "print(random.choice(text_pairs))\n",
        "print(f\"no. of pairs: {len(text_pairs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxxtnbv9D2-u",
        "outputId": "bd753312-8f74-492c-c6ad-ec5992685b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\"Is it the first time you\\'ve been here?\" \"Yes, it\\'s my first visit.\"', '[start] \"¿Es la primera vez que usted está aquí?\" - \"Sí, es mi primera visita.\" [end]')\n",
            "no. of pairs: 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "mcybUiQTD3Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj9HjcGE7h4N",
        "outputId": "8c24e016-922e-4f4f-b756-eadde8d43e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the English and Spanish text pairs\n",
        "# Define which characters to strip out for spanish data- [, ], ¿\n",
        "strip_chars = string.punctuation + \"¿\"  # strip out stadard punctuations + extra one in spanish\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "# Custom standardization function for spanish\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(    # Replace elements of input matching regex pattern with rewrite.\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ],
      "metadata": {
        "id": "kBc6EItWD3C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = tf.range(10)\n",
        "dec_in = seq[:-1]\n",
        "dec_out = seq[1:]\n",
        "\n",
        "print(\"original seq\")\n",
        "print(seq)\n",
        "\n",
        "print(\"dec_in\")\n",
        "print(dec_in)\n",
        "\n",
        "print(\"dec_out\")\n",
        "print(dec_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HndSHekBRwZ",
        "outputId": "c6048e2f-99e5-4223-8df9-1493a52f9a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original seq\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
            "dec_in\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
            "dec_out\n",
            "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing datasets for the translation task\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#IMPORTANT- returns nested tuple- ( (eng_encod_input, spa_ decod_input), spa_decod_output)\n",
        "def format_dataset(eng, spa):\n",
        "    # Q: What are eng and spa pre and post re-assignment ? A: raw text and indices\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,           # encoder input\n",
        "        \"spanish\": spa[:, :-1],    # decoder input Q: what is the first axis?  A: shape = (batch_size, )\n",
        "    }, spa[:, 1:])                  # decoder ouput\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache() #Use in-memory caching to speed up preprocessing.\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "JMicSLvGD3E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A2wVFs8Epoy",
        "outputId": "99711f55-898c-431b-9b72-72dab27a4181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['spanish'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and evaluating the model"
      ],
      "metadata": {
        "id": "54BdC0gg7pQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "-16ZBlBkm9Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed43bdd-5cb4-4a09-8e32-c27ffd8acb55",
        "id": "_wd0SMFiZQJz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1302/1302 [==============================] - 106s 81ms/step - loss: 2.5884 - accuracy: 0.5909 - val_loss: 2.3939 - val_accuracy: 0.6127\n",
            "Epoch 2/2\n",
            "1302/1302 [==============================] - 105s 80ms/step - loss: 2.4194 - accuracy: 0.6174 - val_loss: 2.3251 - val_accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b8f3211fd30>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "transformer.fit(train_ds, epochs=2, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e41c38-5a08-4d1f-fbe3-407d6fdd32d0",
        "scrolled": false,
        "id": "MaPdhwGbwqna"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Did you play tennis yesterday?\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "[start] ayer has tenis en francés [end]\n",
            "-\n",
            "Who invented that?\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "[start] quién escribió eso [end]\n",
            "-\n",
            "As is often the case with young men, he does not pay much attention to his health.\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "    True  True  True  True  True  True False False False]]]\n",
            "[start] como no es la [UNK] con joven para los hombres no se [UNK] mucho atención [end]\n",
            "-\n",
            "He never laughs.\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "**test: mask in not None. mask = [[[ True  True  True False False False False False False False False\n",
            "   False False False False False False False False False]]]\n",
            "[start] Él nunca ha hecho [end]\n"
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(4):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note that both the TransformerEncoder and the TransformerDecoder are shape-invariant, so you could be stacking many of them to create a more powerful encoder or decoder.**"
      ],
      "metadata": {
        "id": "5ije_bIxsnGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://datascienceimages.s3.eu-north-1.amazonaws.com/Language_Translation_using_Transformer_Decoder_Model/Encoder_Decoder_2.png\" width=600px/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "jHJf19zldfi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intriguing Questions:\n",
        "\n",
        "1. Connection between encoder outputs and decoder inputs when there are multiple stacks of them?\n",
        "\n",
        "    **Answer:** The output from the last encoder block acts as input to all decoder blocks.\n",
        "\n",
        "\\\\\n",
        "\n",
        "2. During training, are the decoder inputs obtained from decoder predictions or are they obtained directly from the target data?\n",
        "\n",
        "    **Answer:** During training, the decoder input is obtained directly from the target data. The only differnce between the decoder input and decoder target is an offset of 1 index. For example, consider a hindi to english translation problem with a an english sample \"[start] I like to learn [end]\".  The input to the decoder for this sample will be sample[:-1], i.e. \"[start] I like to learn\" and the target will be sample[1:], i.e. \"I like to learn [end]\". The prediction during training will be a probabilitly distribution over the vocabulary for each element in the sequence. So if the sequence length is 8 and the vocabulary size is 100, then the output shape of the prediction for the given sample will be (6,100). The actual predicted sequence can be computed by taking the argmax, i.e. the token with the maximum probability, for each token in the sequence. An exemplary prediction based on our example can be \"I love to study\". The loss will be computed based on the sum of cross-entropy losses for each token. Here 'like'/'love' and 'learn'/'study' will contribute to the loss.\n",
        "\n",
        "  (Notes:\n",
        "  1. The sample will actually have integer data. Here its written text for the sake of clarity\n",
        "  2. The above explanation is for 1 sample. If the batch size of 64, i.e. 64 samples in a mini-batch , then the decoder output shape is (64,6,100). In general, it is (batch_size, seq_length, vocab_size).\n"
      ],
      "metadata": {
        "id": "xce42Pfp-9vM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other important points:\n",
        "- An advatage of Transformers (over RNNs) is that they allow parallizable computations. Note that the computation of given token does not depend on the computations of the previous token, and can be done in parallel during training.\n",
        "\n",
        "- Note what kind of data structure the the function \"format_dataset(eng, spa)\" returns. It is a nested tuple- ( (eng_encod_input, spa_decod_input), spa_decod_output), where '(eng_encod_input, spa_decod_input)' form the input of the Transformer Model and 'spa_decod_output' is the target output of the Transfomrmer Model."
      ],
      "metadata": {
        "id": "_oX_gVNGnjbI"
      }
    }
  ]
}